---
layout: default
title: Invited Speakers
---

<style>
.speaker-row {
  margin-bottom: 0.2rem;
  padding-bottom: 0.2rem;
  padding: 0.5rem;
  border-radius: 4px;
}

.speaker-row:nth-child(even) {
  background: linear-gradient(135deg, transparent 0%, rgba(144, 86, 86, 0.08) 50%, rgba(144, 86, 86, 0.16) 100%);
}

.speaker-row:nth-child(odd) {
  background: linear-gradient(135deg, rgba(144, 86, 86, 0.16) 0%, rgba(144, 86, 86, 0.08) 50%, transparent 100%);
}

.speaker-row .info {
  margin-bottom: 0;
}
</style>

<h1>Invited Speakers</h1>
<hr class="section-divider">

<p>We have a brilliant line-up of speakers.</p>

<h2>Control and Perception</h2>

<div class="speaker-row">
  <img src="/images/speakers_Lu.jpg" alt="Haojian Lu" class="speaker-photo">
  <div>
    <strong>Haojian Lu</strong><br>
    <div class="info">
      Professor at the Zhejiang University<br>
      Talk: Humanoid robot safety<br>
      Website: <a href="https://person.zju.edu.cn/en/luhaojian">ZJU Profile</a>
    </div>
  </div>
</div>

<div class="speaker-row">
  <img src="/images/speaker_andrea.jpg" alt="Andrea Pupa" class="speaker-photo">
  <div>
    <strong>Andrea Pupa</strong><br>
    <div class="info">
      Assistant Professor at the University of Modena<br>
      Talk: <strong>Human-Robot Collaboration Enhanced: Efficiency and Safety through Speed and Force Control</strong><br>
      Website: <a href="https://www.arscontrol.unimore.it/andrea-pupa/">https://www.arscontrol.unimore.it/andrea-pupa/</a>
    </div>
    <p style="font-size: 0.7rem; color: rgba(65, 64, 64, 0.911); margin-top: 0.8rem; line-height: 1.3; text-align: justify;">
      Human-robot collaboration has revolutionized modern manufacturing settings by combining human flexibility with robotic precision. To guarantee safety, however, the close contact between humans and robots is often translated into overly conservative robot motions. After a brief overview of how to assess safety in HRC from a regulatory point of view, this talk will present two different approaches to deal with safety. The first one, suitable for kinematic robots, reduces the robot's speed as it approaches the human operator, preventing collisions. The second one, suitable for torque-controlled robots, monitors and limits the system's energy to ensure that any contact or collision does not harm the human operator.
    </p>
  </div>
</div>

<h2>Modelling and Design</h2>

<div class="speaker-row">
  <img src="/images/speaker_IvanRuchkin.jpg" alt="Ivan Ruchkin" class="speaker-photo">
  <div>
    <strong>Ivan Ruchkin</strong><br>
    <div class="info">
      Assistant Professor, Department of Electrical and Computer Engineering, University of Florida<br>
      Talk: <strong>Reliable World Models: Physical Grounding and Safety Prediction</strong><br>
      Website: <a href="https://ivan.ece.ufl.edu/">https://ivan.ece.ufl.edu/</a>
    </div>
    <p style="font-size: 0.7rem; color: rgba(65, 64, 64, 0.911); margin-top: 0.8rem; line-height: 1.3; text-align: justify;">
      Autonomous neural controllers pose critical safety challenges in modern robots. To support intervention and adaptation, robots should predict the safety of their future trajectories. However, it is difficult to do for long horizons, especially for rich sensor data under partial observability and distribution shift. The first part of this talk presents a family of deep-learning pipelines for calibrated safety prediction in end-to-end vision-controlled systems. Inspired by world models from reinforcement learning, our pipelines build upon variational autoencoders and recurrent predictors to forecast latent trajectories from raw image sequences. To overcome distribution shift due to compounding prediction errors and changing environmental conditions, we incorporate unsupervised domain adaptation.
    </p>
    <p style="font-size: 0.7rem; color: rgba(65, 64, 64, 0.911); margin-top: 0.5rem; line-height: 1.3; text-align: justify;">
      Unfortunately, learned latent representations in world models lack direct mapping to meaningful physical quantities, limiting their utility and interpretability in downstream planning, control, and safety verification. The second part of this talk argues for a fundamental shift from physically informed to physically interpretable world models. We crystallize four principles that leverage symbolic physical knowledge for interpretable world models: (1) structuring latent spaces, (2) aligning with invariances/equivariances, (3) exploiting supervision with varied strength and granularity, and (4) partitioning generative outputs. The final, third part of this talk dives into an interpretable world model for trajectory prediction. We discuss a novel architecture that aligns learned latent representations with real-world physical quantities by combining a physically interpretable image autoencoding model and a partially known dynamical model.
    </p>
  </div>
</div>

<div class="speaker-row">
  <img src="/images/speaker_sven.jpeg" alt="Sven Parusel" class="speaker-photo">
  <div>
    <strong>Sven Parusel</strong><br>
    <div class="info">
      Franka Robotics<br>
      Talk: <strong>​Safe and Tactile Robots</strong><br>
      Website: <a href="https://de.linkedin.com/in/sven-parusel-66210494">LinkedIn</a>
    </div>
    <p style="font-size: 0.7rem; color: rgba(65, 64, 64, 0.911); margin-top: 0.8rem; line-height: 1.3; text-align: justify;">
      The era of cobots is coming to an end: the new ISO 10218 standards no longer defines collaborative robots, but rather collaborative applications. Robots are entering a new phase defined by tactility, intelligence, and safety by design. This session presents Franka Robotics' approach to safety – from mechanical design and force-sensitive control to modular, workflow-based safety configuration through the Watchman interface. Built upon over a decade of research in physical human-robot interaction, Franka's torque-controlled platforms exemplify a new generation of robots capable of understanding contact, ensuring safety while enabling contact-rich manipulation. The presentation also outlines current benchmarking initiatives on tactile performance and safety validation, highlighting progress towards a reference framework for safe and trustworthy AI Embodiments.
    </p>
  </div>
</div>

<div class="speaker-row">
  <img src="/images/speaker_MartaLa.jpeg" alt="Marta Lagomarsino" class="speaker-photo">
  <div>
    <strong>Marta Lagomarsino</strong><br>
    <div class="info">
      Istituto Italiano di Tecnologia (IIT)<br>
      Talk: Ergonomic and safe robots<br>
      Website: <a href="https://www.iit.it/people-details/-/people/marta-lagomarsino">IIT Profile</a>
    </div>
  </div>
</div>

<!-- h2>Acceptance and Certification</h2> -->
<h2>Deploying and Testing</h2>

<div class="speaker-row">
  <img src="/images/speaker_tapo.jpg" alt="Tapomayukh Bhattacharjee" class="speaker-photo">
  <div>
    <strong>Tapomayukh Bhattacharjee</strong><br>
    <div class="info">
      Assistant Professor at Cornell University<br>
      Talk: <strong>From Lab to Home: Safety in Deploying Physical Caregiving Robot Systems</strong><br>
      Website: <a href="https://emprise.cs.cornell.edu/">https://emprise.cs.cornell.edu/</a>
    </div>
  </div>
</div>

<div class="speaker-row">
  <img src="/images/org_RobinKirschner.png" alt="Robin Kirschner" class="speaker-photo">
  <div>
    <strong>Robin Kirschner</strong><br>
    <div class="info">
      Technical University of Munich (TUM)<br>
      Talk: <strong>Testing robot tactility</strong><br>
      Website: <a href="https://www.ce.cit.tum.de/rsi/team/kirschner-robin/">TUM Profile</a>
    </div>
  </div>
</div>
